{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C6LwkPIW0vu",
        "outputId": "7e880103-aabb-4309-ecc9-606224ad6faa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Using Book 5\n",
            "Extraction complete. Check file1.txt and file2.txt.\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2\n",
        "import PyPDF2\n",
        "from google.colab import files\n",
        "#My DOB is September 27,, 2001 (09-27-2001)\n",
        "birth_month = 9  # September\n",
        "birth_date = 27  # 27th\n",
        "birth_year = 2001  # 2001\n",
        "\n",
        "if birth_month >= 8 and birth_month <= 12:\n",
        "    book_number = (birth_month // 2) + 1\n",
        "else:\n",
        "    book_number = birth_month\n",
        "\n",
        "print(f\"Using Book {book_number}\")\n",
        "\n",
        "pdf_path = \"/content/Harry_Potter_(www.ztcprep.com).pdf\"\n",
        "\n",
        "def extract_pages(pdf_path, start_page, num_pages, output_file):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for i in range(start_page - 1, start_page - 1 + num_pages):\n",
        "            if i < len(reader.pages):\n",
        "                text += reader.pages[i].extract_text()\n",
        "        with open(output_file, 'w', encoding='utf-8') as output:\n",
        "            output.write(text)\n",
        "\n",
        "birth_date_page = 27\n",
        "extract_pages(pdf_path, birth_date_page, 10, \"file1.txt\")\n",
        "\n",
        "birth_year_page = 101\n",
        "extract_pages(pdf_path, birth_year_page, 10, \"file2.txt\")\n",
        "\n",
        "print(\"Extraction complete.file1.txt and file2.txt. have been extracted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R7rq7SteZsW"
      },
      "source": [
        "I began by installing the PyPDF2 library and importing it along with google.colab.files to handle PDFs in Google Colab. Using my birthday (September 27, 2001), I determined the book number (Book 5) and the page numbers to extract. I wrote a function, extract_pages, to extract text from specific pages of the uploaded PDF. For file1.txt, I extracted pages 27–36 (based on my birth date), and for file2.txt, I extracted pages 101–110 (based on my birth year). The extracted text was saved into the respective files, and I confirmed the extraction was successful. Now, file1.txt and file2.txt are ready for further analysis using MapReduce."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKKayhKSXnUn",
        "outputId": "b32d1666-8d46-40f5-9164-7a43ab663760"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word Counts in file1.txt:\n",
            "growing: 1\n",
            "up: 7\n",
            "away: 2\n",
            "from: 2\n",
            "all: 7\n",
            "that: 13\n",
            "until: 1\n",
            "he’: 2\n",
            "s: 13\n",
            "ready: 1\n",
            "to: 23\n",
            "take: 1\n",
            "it?”: 1\n",
            "professor: 12\n",
            "mcgonagall: 7\n",
            "opened: 2\n",
            "her: 6\n",
            "mouth,: 1\n",
            "changed: 2\n",
            "mind,: 1\n",
            "swallowed,: 1\n",
            "and: 51\n",
            "then: 3\n",
            "said,: 1\n",
            "“y: 6\n",
            "es: 1\n",
            "—: 18\n",
            "yes,: 2\n",
            "you’re: 1\n",
            "right,: 1\n",
            "of: 33\n",
            "course.: 1\n",
            "but: 9\n",
            "how: 3\n",
            "is: 2\n",
            "the: 91\n",
            "boy: 5\n",
            "getting: 1\n",
            "here,: 2\n",
            "dumbledore?”: 2\n",
            "she: 5\n",
            "eyed: 1\n",
            "his: 26\n",
            "cloak: 1\n",
            "suddenly: 3\n",
            "as: 16\n",
            "though: 2\n",
            "thought: 1\n",
            "he: 38\n",
            "might: 1\n",
            "be: 4\n",
            "hiding: 1\n",
            "harry: 27\n",
            "underneath: 1\n",
            "it.: 4\n",
            "“hagrid’: 1\n",
            "bringing: 1\n",
            "him.”: 1\n",
            "ou: 1\n",
            "think: 1\n",
            "it: 17\n",
            "wise: 1\n",
            "trust: 2\n",
            "hagrid: 7\n",
            "with: 8\n",
            "something: 3\n",
            "important: 1\n",
            "this?”: 1\n",
            "p: 7\n",
            "a: 47\n",
            "g: 7\n",
            "e: 8\n",
            "|: 7\n",
            "15: 1\n",
            "potter: 10\n",
            "philosophers: 7\n",
            "stone: 7\n",
            "–: 7\n",
            "j.k.: 7\n",
            "rowling: 7\n",
            "“i: 2\n",
            "would: 4\n",
            "my: 2\n",
            "life,”: 1\n",
            "said: 9\n",
            "dumbledore.: 2\n",
            "“i’m: 1\n",
            "not: 7\n",
            "saying: 2\n",
            "heart: 1\n",
            "isn’: 1\n",
            "t: 9\n",
            "in: 15\n",
            "right: 2\n",
            "place,”: 1\n",
            "grudgingly: 1\n",
            ",: 13\n",
            "“but: 2\n",
            "you: 9\n",
            "can’: 2\n",
            "pretend: 1\n",
            "careless.: 1\n",
            "does: 1\n",
            "tend: 1\n",
            "what: 3\n",
            "was: 28\n",
            "that?”: 1\n",
            "low: 2\n",
            "rumbling: 1\n",
            "sound: 2\n",
            "had: 19\n",
            "broken: 1\n",
            "silence: 1\n",
            "around: 2\n",
            "them.: 2\n",
            "grew: 1\n",
            "steadily: 1\n",
            "louder: 1\n",
            "they: 3\n",
            "looked: 7\n",
            "down: 3\n",
            "street: 2\n",
            "for: 6\n",
            "some: 1\n",
            "sign: 2\n",
            "headlight;: 1\n",
            "www.ztcprep.com: 10\n",
            "swelled: 1\n",
            "roar: 2\n",
            "both: 1\n",
            "at: 9\n",
            "sky: 2\n",
            "huge: 1\n",
            "motorcycle: 5\n",
            "fell: 2\n",
            "out: 9\n",
            "air: 2\n",
            "landed: 1\n",
            "on: 18\n",
            "road: 1\n",
            "front: 6\n",
            "if: 2\n",
            "huge,: 1\n",
            "nothing: 2\n",
            "man: 2\n",
            "sitting: 1\n",
            "astride: 1\n",
            "almost: 4\n",
            "twice: 1\n",
            "tall: 1\n",
            "normal: 1\n",
            "least: 1\n",
            "five: 1\n",
            "times: 2\n",
            "wide.: 1\n",
            "simply: 1\n",
            "too: 1\n",
            "big: 1\n",
            "allowed,: 1\n",
            "so: 2\n",
            "wild: 1\n",
            "long: 1\n",
            "tangles: 1\n",
            "bushy: 1\n",
            "black: 3\n",
            "hair: 3\n",
            "beard: 1\n",
            "hid: 1\n",
            "most: 1\n",
            "face,: 2\n",
            "hands: 1\n",
            "size: 1\n",
            "trash: 1\n",
            "can: 2\n",
            "lids,: 1\n",
            "feet: 1\n",
            "their: 5\n",
            "leather: 1\n",
            "boots: 1\n",
            "were: 4\n",
            "like: 4\n",
            "baby: 3\n",
            "dolphins.: 1\n",
            "vast,: 1\n",
            "muscular: 1\n",
            "arms: 2\n",
            "holding: 2\n",
            "bundle: 3\n",
            "blankets.: 2\n",
            "“hagrid,”: 1\n",
            "dumbledore,: 4\n",
            "sounding: 1\n",
            "relieved.: 1\n",
            "“at: 1\n",
            "last.: 1\n",
            "where: 3\n",
            "did: 2\n",
            "get: 6\n",
            "motorcycle?”: 1\n",
            "“borrowed: 1\n",
            "it,: 3\n",
            "sir: 4\n",
            ",”: 4\n",
            "giant,: 1\n",
            "climbing: 1\n",
            "carefully: 1\n",
            "f: 4\n",
            "spoke.: 1\n",
            "oung: 1\n",
            "sirius: 1\n",
            "lent: 1\n",
            "me.: 1\n",
            "i’ve: 1\n",
            "got: 3\n",
            "him,: 2\n",
            ".”: 4\n",
            "“no: 1\n",
            "problems,: 1\n",
            "there?”: 1\n",
            "“no,: 1\n",
            "house: 1\n",
            "destroyed,: 1\n",
            "i: 10\n",
            "him: 4\n",
            "before: 1\n",
            "muggles: 2\n",
            "started: 2\n",
            "swarmin’: 1\n",
            "around.: 1\n",
            "asleep: 2\n",
            "we: 1\n",
            "flyin’: 1\n",
            "over: 8\n",
            "bristol.”: 1\n",
            "16: 1\n",
            "dumbledore: 5\n",
            "bent: 2\n",
            "forward: 1\n",
            "inside,: 1\n",
            "just: 2\n",
            "visible,: 1\n",
            "fast: 1\n",
            "asleep.: 1\n",
            "under: 5\n",
            "tuft: 1\n",
            "jet-black: 1\n",
            "forehead: 1\n",
            "could: 5\n",
            "see: 3\n",
            "curiously: 1\n",
            "shaped: 1\n",
            "cut,: 1\n",
            "bolt: 1\n",
            "lightning.: 1\n",
            "“is: 1\n",
            "?”: 1\n",
            "whispered: 1\n",
            "mcgonagall.: 1\n",
            "es,”: 1\n",
            "“he’ll: 1\n",
            "have: 5\n",
            "scar: 1\n",
            "forever: 1\n",
            "“couldn’: 1\n",
            "do: 2\n",
            "about: 3\n",
            "“even: 1\n",
            "could,: 1\n",
            "wouldn’: 1\n",
            "t.: 1\n",
            "scars: 1\n",
            "come: 1\n",
            "handy: 1\n",
            ".: 15\n",
            "one: 3\n",
            "myself: 1\n",
            "above: 1\n",
            "left: 1\n",
            "knee: 1\n",
            "perfect: 2\n",
            "map: 1\n",
            "london: 1\n",
            "ground.: 1\n",
            "w: 4\n",
            "ell: 1\n",
            "give: 1\n",
            "we’d: 1\n",
            "better: 1\n",
            "this: 3\n",
            "with.”: 1\n",
            "took: 3\n",
            "turned: 3\n",
            "toward: 2\n",
            "dursleys’: 2\n",
            "house.: 1\n",
            "“could: 1\n",
            "say: 1\n",
            "good-bye: 1\n",
            "sir?”: 1\n",
            "asked: 1\n",
            "hagrid.: 1\n",
            "great,: 1\n",
            "shaggy: 1\n",
            "head: 1\n",
            "gave: 1\n",
            "must: 1\n",
            "been: 7\n",
            "very: 7\n",
            "scratchy: 1\n",
            "whiskery: 1\n",
            "kiss.: 1\n",
            "then,: 1\n",
            "let: 2\n",
            "howl: 1\n",
            "wounded: 1\n",
            "dog.: 1\n",
            "“shhh!”: 1\n",
            "hissed: 1\n",
            "mcgonagall,: 1\n",
            "“you’ll: 1\n",
            "wake: 1\n",
            "muggles!”: 1\n",
            "“s-s-sorry: 1\n",
            "sobbed: 1\n",
            "hagrid,: 2\n",
            "taking: 1\n",
            "lar: 3\n",
            "ge,: 1\n",
            "spotted: 1\n",
            "handkerchief: 1\n",
            "burying: 1\n",
            "face: 1\n",
            "c-c-: 1\n",
            "stand: 1\n",
            "lily: 1\n",
            "an’: 2\n",
            "james: 1\n",
            "dead: 1\n",
            "poor: 1\n",
            "little: 2\n",
            "ter: 1\n",
            "live: 1\n",
            "—”: 1\n",
            "es,: 1\n",
            "it’: 1\n",
            "sad,: 1\n",
            "grip: 1\n",
            "yourself,: 1\n",
            "or: 1\n",
            "we’ll: 1\n",
            "found,”: 1\n",
            "whispered,: 1\n",
            "patting: 1\n",
            "gingerly: 1\n",
            "arm: 1\n",
            "stepped: 1\n",
            "garden: 1\n",
            "wall: 1\n",
            "walked: 2\n",
            "door: 5\n",
            "laid: 1\n",
            "gently: 1\n",
            "17: 1\n",
            "doorstep,: 1\n",
            "letter: 2\n",
            "cloak,: 2\n",
            "tucked: 1\n",
            "inside: 2\n",
            "harry’: 1\n",
            "blankets,: 1\n",
            "came: 1\n",
            "back: 5\n",
            "other: 2\n",
            "two.: 1\n",
            "full: 2\n",
            "minute: 1\n",
            "three: 1\n",
            "them: 2\n",
            "stood: 1\n",
            "bundle;: 1\n",
            "hagrid’: 1\n",
            "shoulders: 1\n",
            "shook,: 1\n",
            "blinked: 1\n",
            "furiously: 1\n",
            "twinkling: 1\n",
            "light: 2\n",
            "usually: 1\n",
            "shone: 1\n",
            "dumbledore’: 1\n",
            "eyes: 2\n",
            "seemed: 1\n",
            "gone: 1\n",
            "out.: 1\n",
            "“w: 2\n",
            "ell,”: 1\n",
            "finally: 1\n",
            "“that’: 1\n",
            "that.: 1\n",
            "e’ve: 1\n",
            "no: 3\n",
            "business: 1\n",
            "staying: 1\n",
            "here.: 1\n",
            "may: 1\n",
            "well: 1\n",
            "go: 1\n",
            "join: 1\n",
            "celebrations.”: 1\n",
            "eah,”: 1\n",
            "muf: 1\n",
            "fled: 2\n",
            "voice,: 1\n",
            "“i’d: 1\n",
            "best: 1\n",
            "bike: 2\n",
            "g’night,: 1\n",
            "iping: 1\n",
            "streaming: 1\n",
            "jacket: 1\n",
            "sleeve,: 1\n",
            "swung: 1\n",
            "himself: 1\n",
            "onto: 2\n",
            "kicked: 1\n",
            "engine: 1\n",
            "into: 5\n",
            "life;: 1\n",
            "rose: 2\n",
            "night.: 1\n",
            "shall: 1\n",
            "soon,: 1\n",
            "expect,: 1\n",
            "mcgonagall,”: 1\n",
            "nodding: 1\n",
            "blew: 1\n",
            "nose: 1\n",
            "reply: 1\n",
            "street.: 2\n",
            "corner: 2\n",
            "stopped: 1\n",
            "silver: 1\n",
            "put-: 1\n",
            "outer: 1\n",
            "clicked: 1\n",
            "once,: 1\n",
            "twelve: 1\n",
            "balls: 1\n",
            "sped: 1\n",
            "lamps: 1\n",
            "privet: 3\n",
            "drive: 2\n",
            "glowed: 1\n",
            "orange: 1\n",
            "make: 1\n",
            "tabby: 1\n",
            "cat: 1\n",
            "slinking: 1\n",
            "end: 1\n",
            "blankets: 2\n",
            "step: 1\n",
            "number: 2\n",
            "four: 3\n",
            "“good: 1\n",
            "luck,: 1\n",
            "murmured.: 1\n",
            "heel: 1\n",
            "swish: 1\n",
            "gone.: 1\n",
            "breeze: 1\n",
            "ruf: 1\n",
            "neat: 1\n",
            "hedges: 1\n",
            "drive,: 1\n",
            "which: 2\n",
            "lay: 1\n",
            "silent: 1\n",
            "tidy: 2\n",
            "inky: 1\n",
            "last: 1\n",
            "18: 1\n",
            "place: 1\n",
            "expect: 1\n",
            "astonishing: 1\n",
            "things: 1\n",
            "happen.: 1\n",
            "rolled: 2\n",
            "without: 1\n",
            "waking: 1\n",
            "up.: 1\n",
            "small: 2\n",
            "hand: 1\n",
            "closed: 1\n",
            "beside: 1\n",
            "slept: 1\n",
            "on,: 2\n",
            "knowing: 3\n",
            "special,: 1\n",
            "famous,: 1\n",
            "woken: 2\n",
            "few: 2\n",
            "hours’: 1\n",
            "time: 2\n",
            "by: 3\n",
            "mrs.: 1\n",
            "dursley’: 1\n",
            "scream: 1\n",
            "put: 3\n",
            "milk: 1\n",
            "bottles,: 1\n",
            "nor: 1\n",
            "spend: 1\n",
            "next: 1\n",
            "weeks: 1\n",
            "being: 3\n",
            "prodded: 1\n",
            "pinched: 1\n",
            "cousin: 1\n",
            "dudley: 6\n",
            "…: 1\n",
            "couldn’: 2\n",
            "know: 1\n",
            "moment,: 2\n",
            "people: 1\n",
            "meeting: 1\n",
            "secret: 1\n",
            "country: 1\n",
            "glasses: 1\n",
            "hushed: 1\n",
            "voices:: 1\n",
            "“t: 1\n",
            "o: 1\n",
            "who: 1\n",
            "lived!”: 1\n",
            "19: 1\n",
            "v: 1\n",
            "anashig: 1\n",
            "glass: 1\n",
            "nearly: 1\n",
            "ten: 1\n",
            "years: 2\n",
            "passed: 1\n",
            "since: 1\n",
            "dursleys: 1\n",
            "find: 1\n",
            "nephew: 1\n",
            "step,: 1\n",
            "hardly: 1\n",
            "all.: 1\n",
            "sun: 1\n",
            "same: 3\n",
            "gardens: 1\n",
            "lit: 1\n",
            "brass: 1\n",
            "door;: 1\n",
            "crept: 1\n",
            "living: 2\n",
            "room,: 1\n",
            "exactly: 2\n",
            "night: 1\n",
            "when: 2\n",
            "mr: 1\n",
            "dursley: 2\n",
            "seen: 1\n",
            "fateful: 1\n",
            "news: 1\n",
            "report: 1\n",
            "owls.: 1\n",
            "only: 1\n",
            "photographs: 2\n",
            "mantelpiece: 1\n",
            "really: 2\n",
            "showed: 2\n",
            "much: 1\n",
            "passed.: 1\n",
            "en: 1\n",
            "ago,: 1\n",
            "there: 2\n",
            "lots: 1\n",
            "pictures: 1\n",
            "ge: 2\n",
            "pink: 1\n",
            "beach: 1\n",
            "ball: 1\n",
            "wearing: 1\n",
            "dif: 1\n",
            "ferent-colored: 1\n",
            "bonnets: 1\n",
            "longer: 1\n",
            "now: 1\n",
            "blond: 1\n",
            "riding: 1\n",
            "first: 2\n",
            "bicycle,: 1\n",
            "carousel: 1\n",
            "fair: 1\n",
            "playing: 1\n",
            "computer: 2\n",
            "game: 1\n",
            "father: 1\n",
            "hugged: 1\n",
            "kissed: 1\n",
            "mother: 1\n",
            "room: 1\n",
            "held: 1\n",
            "another: 1\n",
            "lived: 1\n",
            "house,: 1\n",
            "too.: 1\n",
            "y: 1\n",
            "et: 1\n",
            "still: 1\n",
            "there,: 1\n",
            "long.: 1\n",
            "aunt: 4\n",
            "petunia: 1\n",
            "awake: 1\n",
            "20: 1\n",
            "shrill: 1\n",
            "voice: 1\n",
            "made: 1\n",
            "noise: 1\n",
            "day: 1\n",
            "“up!: 1\n",
            "up!: 1\n",
            "now!”: 1\n",
            "woke: 1\n",
            "start.: 1\n",
            "rapped: 1\n",
            "again.: 1\n",
            "“up!”: 1\n",
            "screeched.: 1\n",
            "heard: 1\n",
            "walking: 1\n",
            "kitchen: 1\n",
            "frying: 1\n",
            "pan: 1\n",
            "stove.: 1\n",
            "tried: 1\n",
            "remember: 1\n",
            "dream: 2\n",
            "having.: 1\n",
            "good: 1\n",
            "one.: 1\n",
            "flying: 1\n",
            "funny: 1\n",
            "feeling: 1\n",
            "he’d: 1\n",
            "before.: 1\n",
            "outside: 1\n",
            "“are: 1\n",
            "yet?”: 1\n",
            "demanded.: 1\n",
            "“nearly: 1\n",
            "ell,: 1\n",
            "move: 1\n",
            "want: 2\n",
            "look: 2\n",
            "after: 2\n",
            "bacon.: 1\n",
            "don’: 1\n",
            "dare: 1\n",
            "burn,: 1\n",
            "everything: 1\n",
            "duddy’: 1\n",
            "birthday: 3\n",
            "groaned.: 1\n",
            "“what: 1\n",
            "say?”: 1\n",
            "snapped: 1\n",
            "through: 1\n",
            "“nothing,: 1\n",
            "…”: 1\n",
            "dudley’: 4\n",
            "gotten?: 1\n",
            "slowly: 1\n",
            "bed: 2\n",
            "looking: 1\n",
            "socks.: 1\n",
            "found: 1\n",
            "pair: 1\n",
            "and,: 1\n",
            "pulling: 1\n",
            "spider: 1\n",
            "them,: 2\n",
            "on.: 1\n",
            "used: 1\n",
            "spiders,: 1\n",
            "because: 2\n",
            "cupboard: 1\n",
            "stairs: 1\n",
            "slept.: 1\n",
            "21: 1\n",
            "dressed: 1\n",
            "went: 1\n",
            "hall: 1\n",
            "kitchen.: 1\n",
            "table: 1\n",
            "hidden: 1\n",
            "beneath: 1\n",
            "presents.: 1\n",
            "gotten: 1\n",
            "new: 1\n",
            "wanted,: 1\n",
            "mention: 1\n",
            "second: 1\n",
            "television: 1\n",
            "racing: 2\n",
            "bike.: 1\n",
            "why: 1\n",
            "wanted: 1\n",
            "mystery: 1\n",
            "fat: 1\n",
            "hated: 1\n",
            "exercise: 1\n",
            "unless: 1\n",
            "course: 1\n",
            "involved: 1\n",
            "punching: 2\n",
            "somebody: 1\n",
            "favorite: 1\n",
            "bag: 1\n",
            "often: 1\n",
            "catch: 1\n",
            "him.: 1\n",
            "didn’: 1\n",
            "fast.: 1\n",
            "perhaps: 1\n",
            "dark: 1\n",
            "cupboard,: 1\n",
            "always: 1\n",
            "skinny: 1\n",
            "age.: 1\n",
            "even: 1\n",
            "smaller: 1\n",
            "skinnier: 1\n",
            "than: 2\n",
            "wear: 1\n",
            "old: 1\n",
            "clothes: 1\n",
            "s,: 1\n",
            "bigger: 1\n",
            "was.: 1\n",
            "thin: 1\n",
            "knobbly: 1\n",
            "knees,: 1\n",
            "bright: 1\n",
            "green: 1\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def map_reduce_word_count(file_path):\n",
        "    word_count = defaultdict(int)\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            words = line.strip().split()\n",
        "            for word in words:\n",
        "                word_count[word.lower()] += 1\n",
        "    return word_count\n",
        "\n",
        "word_count = map_reduce_word_count(\"file1.txt\")\n",
        "print(\"Word Counts in file1.txt:\")\n",
        "for word, count in word_count.items():\n",
        "    print(f\"{word}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R9kU3EBeret"
      },
      "source": [
        "I used the defaultdict from the collections module to create a word frequency counter. The function map_reduce_word_count reads file1.txt, splits the text into words, and counts the occurrences of each word in a case-insensitive manner. After processing, it prints each word along with its frequency, providing a clear overview of how many times each word appears in the extracted text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM2aMwfMZgdI",
        "outputId": "f8536dc8-ac8d-4d57-9446-1d07514b6c78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.11/dist-packages (0.8.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspellchecker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPjnSEr8Zsh0",
        "outputId": "a31f13ab-28f8-49df-84f1-b10266924299"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hagrid: 27\n",
            "ter: 19\n",
            "www: 10\n",
            "ztcprep: 10\n",
            "yeh: 10\n",
            "ll: 7\n",
            "ernon: 6\n",
            "didn: 6\n",
            "gringotts: 5\n",
            "hadn: 3\n",
            "ve: 3\n",
            "stuf: 3\n",
            "ap: 3\n",
            "wasn: 2\n",
            "albus: 2\n",
            "gettin: 2\n",
            "knuts: 2\n",
            "izards: 2\n",
            "eah: 2\n",
            "64: 1\n",
            "muggle: 1\n",
            "goin: 1\n",
            "dumbled: 1\n",
            "ying: 1\n",
            "insul: 1\n",
            "65: 1\n",
            "shouldn: 1\n",
            "speakin: 1\n",
            "aren: 1\n",
            "meself: 1\n",
            "66: 1\n",
            "ou: 1\n",
            "67: 1\n",
            "diagon: 1\n",
            "ther: 1\n",
            "68: 1\n",
            "payin: 1\n",
            "deliverin: 1\n",
            "69: 1\n",
            "mm: 1\n",
            "wouldn: 1\n",
            "teh: 1\n",
            "70: 1\n",
            "cept: 1\n",
            "fetchin: 1\n",
            "everythin: 1\n",
            "pposed: 1\n"
          ]
        }
      ],
      "source": [
        "from spellchecker import SpellChecker\n",
        "import re \n",
        "def non_eng_mapper(text):\n",
        "    words = re.findall(r'\\w+', text.lower()) \n",
        "    map_output = defaultdict(int)\n",
        "    for word in words:\n",
        "        map_output[word] += 1\n",
        "    return map_output\n",
        "def non_eng_reducer(map_output):\n",
        "    word_counts = defaultdict(int)\n",
        "    for counts in map_output:\n",
        "        for word, count in counts.items():\n",
        "            word_counts[word] += count\n",
        "    return word_counts\n",
        "def non_eng_words(word_counts, spell_checker):\n",
        "    non_eng_cnt = defaultdict(int)\n",
        "    for word, count in word_counts.items():\n",
        "        if not spell_checker.known([word]):  \n",
        "            non_eng_cnt[word] += count\n",
        "    return non_eng_cnt\n",
        "\n",
        "with open('file2.txt', 'r') as file2:\n",
        "    text = file2.read()\n",
        "spell_check = SpellChecker() \n",
        "map_output = non_eng_mapper(text)\n",
        "word_counts = non_eng_reducer([map_output])\n",
        "non_eng_counts = non_eng_words(word_counts, spell_check) \n",
        "for word, count in sorted(non_eng_counts.items(), key=lambda x: x[1], reverse=True):\n",
        "    print(f'{word}: {count}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBO9gwJ1e3Dm"
      },
      "source": [
        "I used the SpellChecker library to identify non-English words in file2.txt. The non_eng_mapper function splits the text into words and counts their occurrences, while the non_eng_reducer aggregates these counts. The non_eng_words function filters out words not recognized by the spell checker as English, counting only non-English words. Finally, the code prints the non-English words and their frequencies in descending order, providing a clear summary of unique terms like names, places, or spells from the Harry Potter universe"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
